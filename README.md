# ðŸ¤– ESP32-CAM AI Follow-Me Robot

An AI-powered mobile robot that tracks a human hand using real-time computer vision and responds with autonomous movement, obstacle avoidance, and wireless control. Built using the ESP32-CAM module, Arduino Mega, and Python-based control via Gradio.

![Robot Demo](images/robot_following_hand.jpg)

---

## ðŸš€ Project Overview

This project demonstrates the integration of embedded systems, computer vision, and web technologies to build a smart robot capable of:

* ðŸ‘‹ Following a user's hand using MediaPipe & OpenCV
* ðŸš§ Avoiding obstacles in real time using an ultrasonic sensor
* ðŸŽ® Switching to manual control via a custom web UI (Gradio)
* ðŸ¤– Entering Random Personality Mode after idle time
* ðŸ’ƒ Executing a Dance Mode upon user command
* ðŸ”´ Displaying RGB LED status feedback

---

## ðŸ§  System Architecture

User Hand â†’ ESP32-CAM â†’ Laptop (Python + MediaPipe) â†’ ESP32-CAM (HTTP) â†’ Arduino Mega (Serial) â†’ Motors + Sensors

See `images/architecture_diagram.png` for the full visual flow.

---

## ðŸ”Œ Hardware Components

| Component          | Purpose                                  |
| ------------------ | ---------------------------------------- |
| ESP32-CAM          | Video stream + receives HTTP commands    |
| Arduino Mega       | Controls motors, sensors, and LED        |
| L298N Motor Driver | Drives 4 DC motors                       |
| HC-SR04 Sensor     | Detects obstacles < 20cm                 |
| RGB LED            | Visual feedback for system status        |
| 4x DC Motors       | Movement (forward, backward, turn)       |
| Battery & Switches | Power logic and motor systems separately |

---

## ðŸ’» Software Stack

* **Python 3.10+**

  * `MediaPipe` â€“ for hand tracking
  * `OpenCV` â€“ for video frame processing
  * `Gradio` â€“ for web UI
  * `Requests` â€“ for HTTP communication

* **Arduino IDE**

  * Serial command reading
  * Obstacle logic and motor control

---

## ðŸ“ File Structure

ðŸ“„ hand\_tracking.py  # ðŸ–ï¸ Detects hand using MediaPipe and sends movement commands to the robot

ðŸ“„ robot\_ui.py  # ðŸŒ Gradio web interface for manual robot control

ðŸ“„ arduino\_code.ino  # ðŸ”§ Arduino Mega code controlling motors, sensors, and RGB LED

ðŸ“ images/  # ðŸ–¼ï¸ Contains architecture diagram and robot demonstration images



---

## ðŸŽ¥ Demo Highlights

| Mode               | Description                              |
| ------------------ | ---------------------------------------- |
| Follow-Me Mode     | Tracks hand using landmark coordinates   |
| Obstacle Avoidance | Stops and turns when < 20cm object ahead |
| Random Personality | Randomly moves if no hand for 30+ secs   |
| Dance Mode         | Spins and moves in a preset pattern      |

![Obstacle Avoidance](images/obstacle_avoidance_during.jpg)

---

## ðŸ‘¥ Team Members

* Abdullah Hani Abdellatif Al-Shobaki â€“ 2284612
* Mohamed Aiman Mohamed Alkozendar â€“ 2283149
* Mohammed Ahmed Mohammed Al-labani â€“ 2105990

Special thanks to:

* **Prof. Mahmut AÄŸan** â€“ Project Supervisor
* **Fahd Al-Sattaf** â€“ Hardware support & wiring

---

## ðŸ“š References

* [MediaPipe â€“ Google Research](https://github.com/google/mediapipe)
* [OpenCV](https://opencv.org)
* [ESP32-CAM Documentation](https://docs.espressif.com/projects/esp-idf/en/latest/esp32/hw-reference/esp32/get-started-cam.html)
* [Gradio](https://www.gradio.app)
* [HC-SR04 Datasheet](https://components101.com/sensors/hc-sr04-ultrasonic-sensor)
* [ChatGPT-4o â€“ OpenAI](https://chat.openai.com)

---

## ðŸ“Œ License

This project is for educational purposes only.
